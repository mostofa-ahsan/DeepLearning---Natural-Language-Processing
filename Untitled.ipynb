{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.138616</td>\n",
       "      <td>-1.045398</td>\n",
       "      <td>-3.014997</td>\n",
       "      <td>-2.298535</td>\n",
       "      <td>-1.863517</td>\n",
       "      <td>-1.778439</td>\n",
       "      <td>-1.808979</td>\n",
       "      <td>-1.749049</td>\n",
       "      <td>39.643519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.078073</td>\n",
       "      <td>-1.006432</td>\n",
       "      <td>-2.738358</td>\n",
       "      <td>-1.912109</td>\n",
       "      <td>-1.742987</td>\n",
       "      <td>-1.737180</td>\n",
       "      <td>-1.751221</td>\n",
       "      <td>-1.692798</td>\n",
       "      <td>41.735507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.028027</td>\n",
       "      <td>-0.974721</td>\n",
       "      <td>-2.115120</td>\n",
       "      <td>-1.471614</td>\n",
       "      <td>-1.506228</td>\n",
       "      <td>-1.578796</td>\n",
       "      <td>-1.580329</td>\n",
       "      <td>-1.542716</td>\n",
       "      <td>43.703867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.009270</td>\n",
       "      <td>-0.960210</td>\n",
       "      <td>-1.919396</td>\n",
       "      <td>-1.304812</td>\n",
       "      <td>-1.449832</td>\n",
       "      <td>-1.525372</td>\n",
       "      <td>-1.527216</td>\n",
       "      <td>-1.494168</td>\n",
       "      <td>45.597525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.989596</td>\n",
       "      <td>-0.914237</td>\n",
       "      <td>-2.069754</td>\n",
       "      <td>-1.322835</td>\n",
       "      <td>-1.723560</td>\n",
       "      <td>-1.509199</td>\n",
       "      <td>-1.558725</td>\n",
       "      <td>-1.520486</td>\n",
       "      <td>47.443761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0 -1.138616 -1.045398 -3.014997 -2.298535 -1.863517 -1.778439 -1.808979   \n",
       "1 -1.078073 -1.006432 -2.738358 -1.912109 -1.742987 -1.737180 -1.751221   \n",
       "2 -1.028027 -0.974721 -2.115120 -1.471614 -1.506228 -1.578796 -1.580329   \n",
       "3 -1.009270 -0.960210 -1.919396 -1.304812 -1.449832 -1.525372 -1.527216   \n",
       "4 -0.989596 -0.914237 -2.069754 -1.322835 -1.723560 -1.509199 -1.558725   \n",
       "\n",
       "         f8      label  \n",
       "0 -1.749049  39.643519  \n",
       "1 -1.692798  41.735507  \n",
       "2 -1.542716  43.703867  \n",
       "3 -1.494168  45.597525  \n",
       "4 -1.520486  47.443761  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "\n",
    "# l= [\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"label\"]\n",
    "df= pd.read_csv(\"C:/Users/mkahs/REPOSITORY/DeepLearning---Natural-Language-Processing/Arup.csv\", header=None, names=[\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"label\"])\n",
    "# df = pd.ExcelFile(r\"C:/Users/mkahs/REPOSITORY/DeepLearning---Natural-Language-Processing/Residential-Building-Data-Set.xlsx\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39.643519\n",
       "1    41.735507\n",
       "2    43.703867\n",
       "3    45.597525\n",
       "4    47.443761\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df.loc[0:629]\n",
    "# print(len(train))\n",
    "# train.head()\n",
    "Xtrain = train.iloc[:,0:8]\n",
    "Ytrain = train.iloc[:,8]\n",
    "Ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630    29.102066\n",
       "631    37.723714\n",
       "632    46.305973\n",
       "633    54.852359\n",
       "634    56.625521\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.loc[630:944]\n",
    "# print(len(test))\n",
    "# test.tail()\n",
    "Xtest = test.iloc[:,0:8]\n",
    "Ytest = test.iloc[:,8]\n",
    "Ytest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mkahs\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mkahs\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mkahs\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mkahs\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mkahs\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mkahs\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Larger: -624.89 (870.68) MSE\n"
     ]
    }
   ],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, Xtrain, Ytrain, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4b5afcc58056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mYtrain\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Ytrain= Ytrain.reshape(-1,1)\n",
    "\n",
    "Ytest= Ytest.reshape(-1,1)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "Xtrain = sc_X.fit_transform(Xtrain)\n",
    "\n",
    "sc_Y = StandardScaler()\n",
    "Ytrain = sc_Y.fit_transform(Ytrain)\n",
    "\n",
    "\n",
    "sc_Xt = StandardScaler()\n",
    "Xtest = sc_Xt.fit_transform(Xtest)\n",
    "\n",
    "sc_Yt = StandardScaler()\n",
    "Ytest = sc_Yt.fit_transform(Ytest)\n",
    "# Create Sequential model with Dense layers, using the add method\n",
    "model = Sequential()\n",
    "\n",
    "#Dense implements the operation:\n",
    "#        output = activation(dot(input, kernel) + bias)\n",
    "#Units are the dimensionality of the output space for the layer,\n",
    "#     which equals the number of hidden units\n",
    "#Activation and loss functions may be specified by strings or classes\n",
    "###########################################################\n",
    "# model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "# model.add(Dense(units=10, activation='softmax'))\n",
    "# model.add(Dense(1, kernel_initializer='normal'))\n",
    "##################################################\n",
    "\n",
    "model.add(Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "#The compile method configures the modelâ€™s learning process\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#The fit method does the training in batches\n",
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(Xtrain, Ytrain, epochs=50, batch_size=32)\n",
    "\n",
    "#The evaluate method calculates the losses and metrics\n",
    "#     for the trained model\n",
    "loss_and_metrics = model.evaluate(Xtest, Ytest, batch_size=128)\n",
    "\n",
    "#The predict method applies the trained model to inputs\n",
    "#     to generate outputs\n",
    "classes = model.predict(x_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630     29.102066\n",
      "631     37.723714\n",
      "632     46.305973\n",
      "633     54.852359\n",
      "634     56.625521\n",
      "          ...    \n",
      "940    214.124102\n",
      "941    214.610637\n",
      "942    215.056806\n",
      "943    215.499522\n",
      "944    215.942238\n",
      "Name: label, Length: 315, dtype: float64\n",
      "[ 81.54849   78.96885   76.725555  75.646355  74.773415  75.62657\n",
      "  74.89153   75.16223   72.557304  75.12021   74.23236   74.42836\n",
      "  74.64102   77.57557   77.772964  78.75879   79.1226    79.669586\n",
      "  76.28223   77.088486  73.59665   76.3864    76.92677   77.67971\n",
      "  78.235565  78.61883   78.82175   78.05161   79.17792   78.45114\n",
      "  75.05347   75.60637   74.077194  76.967224  76.533005  77.271034\n",
      "  76.272415  78.04535   78.28126   78.62498   78.65419   77.84293\n",
      "  77.83231   77.92016   78.4101    79.182816  75.54018   79.053894\n",
      "  79.39791   79.42309   80.17806   79.64775   80.42974   80.11603\n",
      "  80.39395   81.53483   80.75639   76.237854  81.21069   81.271736\n",
      "  81.17377   81.992935  82.37092   82.916435  75.713905  77.89139\n",
      "  79.00514   79.73784   80.1115    80.47329   80.74969   80.9467\n",
      "  81.26218   81.49341   81.79284   77.37382   81.3765    80.13905\n",
      "  83.16704   82.86643   83.56119   79.69012   84.50389   82.1667\n",
      "  86.40201   83.79193   77.83991   83.97479   87.54574   87.73504\n",
      "  85.19326   85.58623   88.625656  89.39575   86.67365   87.38449\n",
      "  78.899124  82.23496   82.3461    83.39682   83.8976    84.70177\n",
      "  85.0148    85.513275  85.827545  86.42296   86.825806  80.39328\n",
      "  87.22839   87.71367   87.995224  88.33188   89.07313   89.40886\n",
      "  89.96638   90.46526   91.564316  96.573746  81.03587   97.754776\n",
      "  92.87752   99.01624   99.379105 100.816986 101.54297  101.4845\n",
      "  95.714355 101.776     80.58725   85.48691   86.161674  87.79809\n",
      "  88.73143   89.40621   90.48665   91.806755  93.01498   98.035995\n",
      "  99.0909    82.517914 100.220215 101.219376 101.78404  102.97553\n",
      " 104.10268  103.9003   105.13512  106.61125  106.79611   84.6539\n",
      " 107.69086  109.88425  108.868195 109.16452  110.197014 111.12201\n",
      " 111.7653   113.572754 115.403305 117.99654   83.504036  91.99028\n",
      "  96.38943   97.53729   98.13467   98.88872   98.30512   98.53827\n",
      "  99.274475  98.8253    99.493546  88.92039  100.77084   99.150955\n",
      " 100.98768  101.68474  103.311966 104.07389  105.5455   105.78118\n",
      " 106.71713  106.884346  90.46722  107.91994  108.47646  108.798004\n",
      " 108.91344  110.48668  110.347244 112.81517  114.07817  115.28462\n",
      "  95.09639  101.566574 105.53467  106.45444  108.1983   110.00362\n",
      " 110.362564 110.94603  111.53709  111.91927  111.5449    98.74752\n",
      " 112.16792  112.94681  113.43158  113.915695 114.75157  115.098495\n",
      " 115.59866  115.67352  116.828064 117.139786  99.388885 118.73127\n",
      " 119.34922  120.30821  120.61992  121.417076 121.97487  125.02116\n",
      " 125.24295  125.845276 104.243195 115.903564 118.58328  119.890854\n",
      " 121.951256 122.57279  123.61986  123.992905 126.58983  128.03342\n",
      " 129.5983   109.22119  129.3036   131.8654   133.8733   136.75714\n",
      " 135.02635  136.29759  136.41191  137.76584  140.64464  112.48193\n",
      " 138.15877  140.92175  141.14534  143.36618  143.50764  144.31502\n",
      " 144.3054   144.6439   146.4725   149.65338  136.23726  142.5125\n",
      " 146.12463  149.9933   153.49657  157.20276  160.51234  161.24379\n",
      " 164.10323  166.61014  164.71034  137.64578  165.08278  165.56218\n",
      " 168.59651  169.3704   171.85974  172.7098   175.99408  178.44188\n",
      " 179.42863  181.30342  138.85133  181.41731  182.90546  145.16075\n",
      " 146.8694   148.3773   149.43625  152.4522   154.30371  155.67516\n",
      " 128.19272  133.39235  133.86452  136.48691  137.23601  139.91447\n",
      " 141.34087  141.60768  140.19228  139.31903  137.42316  131.36269\n",
      " 136.66791  135.1024   135.73808  136.85925  137.38206  137.12032\n",
      " 137.66966  136.64792  137.53604  136.13518  133.28369  135.13107\n",
      " 134.4673   136.30879  138.29634 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "# evaluate model with standardized dataset\n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "estimators=KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)\n",
    "# pipeline = Pipeline(estimators)\n",
    "# kfold = KFold(n_splits=10)\n",
    "estimators.fit(Xtrain,Ytrain)\n",
    "predictions= estimators.predict(Xtest)\n",
    "print(Ytest)\n",
    "print(predictions)\n",
    "# print(Y)\n",
    "# print(sc_X.inverse_transform(predictions))\n",
    "# results = cross_val_score(pipeline, Xtrain, Ytrain, cv=kfold)\n",
    "# print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "# model.fit(Xtrain, Ytrain, epochs=50, batch_size=32)\n",
    "# loss_and_metrics = model.evaluate(Xtest, Ytest, batch_size=128)\n",
    "# classes = model.predict(x_test, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
